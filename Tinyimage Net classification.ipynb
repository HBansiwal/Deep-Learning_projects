{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=[]\n",
    "#size_100 = (100,100)\n",
    "for f in os.listdir('D:/ML/ImageNetModel/mini_train'):\n",
    "    if f.endswith('.JPEG'):\n",
    "        #print(f)\n",
    "        path.append(\"D:/ML/ImageNetModel/mini_train/\"+f)\n",
    "        addr=shuffle(path)\n",
    "print(addr[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_creat(start,batchsize,new_size):\n",
    "    data=[]\n",
    "    label=[]\n",
    "    batch=addr[start:start+batchsize]\n",
    "    for i in range(batchsize):\n",
    "        img=cv2.imread(batch[i])\n",
    "        img.resize(new_size,new_size,3)#rgb=3\n",
    "        data.append(img)\n",
    "    for j in range(batchsize):\n",
    "        name=batch[j].split('/')[-1]\n",
    "        name=name.split('.')[-2]\n",
    "        name=name.split('_')[-2]\n",
    "        if(name=='n01443537'):\n",
    "            label.append([1,0,0,0,0,0,0,0,0,0])\n",
    "        elif(name=='n01629819'):\n",
    "            label.append([0,1,0,0,0,0,0,0,0,0])\n",
    "        elif(name=='n01641577'):\n",
    "            label.append([0,0,1,0,0,0,0,0,0,0])\n",
    "        elif(name=='n01698640'):\n",
    "            label.append([0,0,0,1,0,0,0,0,0,0])\n",
    "        elif(name=='n01644900'):\n",
    "            label.append([0,0,0,0,1,0,0,0,0,0])\n",
    "        elif(name=='n01742172'):\n",
    "            label.append([0,0,0,0,0,1,0,0,0,0])\n",
    "        elif(name=='n01768244'):\n",
    "            label.append([0,0,0,0,0,0,1,0,0,0])\n",
    "        elif(name=='n01770393'):\n",
    "            label.append([0,0,0,0,0,0,0,1,0,0])\n",
    "        elif(name=='n01774384'):\n",
    "            label.append([0,0,0,0,0,0,0,0,1,0])\n",
    "        \n",
    "        else:\n",
    "            label.append([0,0,0,0,0,0,0,0,0,1])\n",
    "    return data,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data,label=batch_creat(0,100,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(np.shape(data))\n",
    "#print(np.shape(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_path=[]\n",
    "#size_100 = (100,100)\n",
    "for n in os.listdir('D:/ML/ImageNetModel/mini_test'):\n",
    "    if n.endswith('.JPEG'):\n",
    "        #print(f)\n",
    "        t_path.append(\"D:/ML/ImageNetModel/mini_test/\"+n)\n",
    "        t_addr=shuffle(t_path)\n",
    "print(t_addr[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_batch_creat(t_start,t_batchsize,t_new_size):\n",
    "    t_data=[]\n",
    "    t_label=[]\n",
    "    t_batch=t_addr[t_start:t_start+t_batchsize]\n",
    "    for i in range(t_batchsize):\n",
    "        img=cv2.imread(t_batch[i])\n",
    "        img.resize(t_new_size,t_new_size,3)#rgb=3\n",
    "        t_data.append(img)\n",
    "    for j in range(t_batchsize):\n",
    "        t_name=t_batch[j].split('/')[-1]\n",
    "        t_name=t_name.split('.')[-2]\n",
    "        t_name=t_name.split('_')[-2]\n",
    "        if(t_name=='n01443537'):\n",
    "            t_label.append([1,0,0,0,0,0,0,0,0,0])\n",
    "        elif(t_name=='n01629819'):\n",
    "            t_label.append([0,1,0,0,0,0,0,0,0,0])\n",
    "        elif(t_name=='n01641577'):\n",
    "            t_label.append([0,0,1,0,0,0,0,0,0,0])\n",
    "        elif(t_name=='n01698640'):\n",
    "            t_label.append([0,0,0,1,0,0,0,0,0,0])\n",
    "        elif(t_name=='n01644900'):\n",
    "            t_label.append([0,0,0,0,1,0,0,0,0,0])\n",
    "        elif(t_name=='n01742172'):\n",
    "            t_label.append([0,0,0,0,0,1,0,0,0,0])\n",
    "        elif(t_name=='n01768244'):\n",
    "            t_label.append([0,0,0,0,0,0,1,0,0,0])\n",
    "        elif(t_name=='n01770393'):\n",
    "            t_label.append([0,0,0,0,0,0,0,1,0,0])\n",
    "        elif(t_name=='n01774384'):\n",
    "            t_label.append([0,0,0,0,0,0,0,0,1,0])\n",
    "        \n",
    "        else:\n",
    "            t_label.append([0,0,0,0,0,0,0,0,0,1])\n",
    "        \n",
    "    return t_data,t_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_data, t_label=t_batch_creat(0,440,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(t_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_path=[]\n",
    "#size_100 = (100,100)\n",
    "for m in os.listdir('D:/ML/ImageNetModel/mini_val'):\n",
    "    if m.endswith('.JPEG'):\n",
    "        #print(f)\n",
    "        val_path.append(\"D:/ML/ImageNetModel/mini_val/\"+m)\n",
    "        val_addr=shuffle(val_path)\n",
    "print(val_addr[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_batch_creat(val_start,val_batchsize,val_new_size):\n",
    "    val_data=[]\n",
    "    val_label=[]\n",
    "    val_batch=val_addr[val_start:val_start+val_batchsize]\n",
    "    for i in range(val_batchsize):\n",
    "        img=cv2.imread(val_batch[i])\n",
    "        img.resize(val_new_size,val_new_size,3)#rgb=3\n",
    "        val_data.append(img)\n",
    "    for j in range(val_batchsize):\n",
    "        val_name=val_batch[j].split('/')[-1]\n",
    "        val_name=val_name.split('.')[-2]\n",
    "        val_name=val_name.split('_')[-2]\n",
    "        if(val_name=='n01443537'):\n",
    "            val_label.append([1,0,0,0,0,0,0,0,0,0])\n",
    "        elif(val_name=='n01629819'):\n",
    "            val_label.append([0,1,0,0,0,0,0,0,0,0])\n",
    "        elif(val_name=='n01641577'):\n",
    "            val_label.append([0,0,1,0,0,0,0,0,0,0])\n",
    "        elif(val_name=='n01698640'):\n",
    "            val_label.append([0,0,0,1,0,0,0,0,0,0])\n",
    "        elif(val_name=='n01644900'):\n",
    "            val_label.append([0,0,0,0,1,0,0,0,0,0])\n",
    "        elif(val_name=='n01742172'):\n",
    "            val_label.append([0,0,0,0,0,1,0,0,0,0])\n",
    "        elif(val_name=='n01768244'):\n",
    "            val_label.append([0,0,0,0,0,0,1,0,0,0])\n",
    "        elif(val_name=='n01770393'):\n",
    "            val_label.append([0,0,0,0,0,0,0,1,0,0])\n",
    "        elif(val_name=='n01774384'):\n",
    "            val_label.append([0,0,0,0,0,0,0,0,1,0])\n",
    "        \n",
    "        else:\n",
    "            val_label.append([0,0,0,0,0,0,0,0,0,1])\n",
    "    return val_data, val_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data,val_label=val_batch_creat(0,440,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(val_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(np.shape(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(np.shape(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)#truncated, anything outside -0.2 and 0.2 has a probability of occurence 0\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)#constant array of 0.1 with whatever shape we give to it\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, 64,64,3])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_conv1 = weight_variable([5, 5, 3, 32])#5X5 filter 1 is the in channel (rbg) and there are 32 feature maps\n",
    "b_conv1 = bias_variable([32])#32 feature maps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_conv1 = tf.nn.relu(conv2d(x, W_conv1) + b_conv1)#64X28X28X32. Here 64 is the batch size (assumed)\n",
    "h_pool1 = max_pool_2x2(h_conv1)#max pooling 64X14X14X32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# conv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_conv2 = weight_variable([5, 5, 32, 64])#64X32X32X64\n",
    "b_conv2 = bias_variable([64])\n",
    "\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)#64X16X16X64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# conv3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#W_conv3 = weight_variable([5, 5, 64, 128])#128X64X64X128\n",
    "#b_conv3 = bias_variable([128])\n",
    "\n",
    "#h_conv3 = tf.nn.relu(conv2d(h_pool2, W_conv3) + b_conv3)\n",
    "#h_pool3 = max_pool_2x2(h_conv3)#128X32X32X128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_fc1 = weight_variable([16 * 16 * 64, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 16*16*64])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#W_fc2 = weight_variable([32 * 32 * 128, 2048])\n",
    "#b_fc2 = bias_variable([2048])\n",
    "\n",
    "#h_pool3_flat = tf.reshape(h_pool2, [-1, 32*32*128])\n",
    "#h_fc2 = tf.nn.relu(tf.matmul(h_pool3_flat, W_fc2) + b_fc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_prob = tf.placeholder(tf.float32)#probability of retaining the neurons. 0=all neurons dropped, 1 means no neuron is dropped\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_fc2 = weight_variable([1024,10])\n",
    "b_fc2 = bias_variable([10])\n",
    "\n",
    "y = tf.matmul(h_fc1_drop, W_fc2) + b_fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#val_x, val_y=batch_creat(0,231,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:#declaring tf.Session as sess\n",
    "    sess.run(tf.global_variables_initializer())#initializing all the variables we used\n",
    "    for j in range(10):\n",
    "        for i in range(5):#number of iterations we are using\n",
    "            batchData,batchLabel = batch_creat(i*25, 25, 64) #taking the slice of input data\n",
    "            train_accuracy = accuracy.eval(feed_dict={x:batchData , y_: batchLabel, keep_prob: 1.0})#training accuracy calculated with no dropout probabilty\n",
    "            print('step %d, training accuracy %g' % (i, train_accuracy))\n",
    "            cost=cross_entropy.eval(feed_dict={x:batchData , y_: batchLabel, keep_prob: 1.0}) \n",
    "            #print(cost/100)\n",
    "            train_step.run(feed_dict={x: batchData, y_: batchLabel, keep_prob: 0.7})#dropout probabilty during training is kept 0.5\n",
    "        print('validation accuracy ', accuracy.eval(feed_dict={x: val_data, y_: val_label, keep_prob: 1.0}))#val accuracy\n",
    "    print('test accuracy ', accuracy.eval(feed_dict={x: t_data, y_: t_label, keep_prob: 1.0}))#test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
